{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 pytorch tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "torch.manual_seed(446)\n",
    "np.random.seed(446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_numpy, x_torch\n",
      "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
      "\n",
      "to and from numpy and pytorch\n",
      "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
      "\n",
      "x+y\n",
      "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
      "\n",
      "norm\n",
      "0.37416573867739417 tensor(0.3742)\n",
      "mean along the 0th dimension\n",
      "[2. 3.] tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "## Tensors and relation to numpy\n",
    "\n",
    "# we create tensors in a similar way to numpy nd arrays\n",
    "x_numpy = np.array([0.1, 0.2, 0.3])\n",
    "x_torch = torch.tensor([0.1, 0.2, 0.3])\n",
    "print('x_numpy, x_torch')\n",
    "print(x_numpy, x_torch)\n",
    "print()\n",
    "\n",
    "# to and form numpy, pytorch\n",
    "print('to and from numpy and pytorch')\n",
    "print(torch.from_numpy(x_numpy), x_torch.numpy())\n",
    "print()\n",
    "\n",
    "# we can do basic operations like +-*/ \n",
    "y_numpy = np.array([3, 4, 5.])\n",
    "y_torch = torch.tensor([3, 4, 5.])\n",
    "print(\"x+y\")\n",
    "print(x_numpy + y_numpy, x_torch + y_torch)\n",
    "print()\n",
    "\n",
    "\n",
    "# many functions that are in numpy are also in pytorch\n",
    "print(\"norm\")\n",
    "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\n",
    "print\n",
    "\n",
    "# to apply an operation along a dimension\n",
    "# we use the dim keyword argument instead of axis\n",
    "print(\"mean along the 0th dimension\")\n",
    "x_numpy = np.array([[1,2],[3,4.]])\n",
    "x_torch = torch.tensor([[1,2],[3,4.]])\n",
    "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 28, 28])\n",
      "torch.Size([1000, 3, 784])\n",
      "torch.Size([1000, 3, 784])\n"
     ]
    }
   ],
   "source": [
    "## Tensor.view\n",
    "\n",
    "# \"MNIST\"\n",
    "N, C, W, H = 1000, 3, 28, 28\n",
    "X = torch.randn((N, C, W, H))\n",
    "\n",
    "print(X.shape)\n",
    "print(X.view(N, C, 784).shape)\n",
    "print(X.view(-1, C, 784).shape) # automatically choose the 0th dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "## Broadcasting semantics\n",
    "\n",
    "# Pytorch operations support Numpy Broadcasting Semantics\n",
    "x = torch.empty(5, 1, 4, 1)\n",
    "y = torch.empty(   3, 1, 1)\n",
    "print((x + y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c tensor(3., grad_fn=<AddBackward0>)\n",
      "d tensor(2., grad_fn=<AddBackward0>)\n",
      "e tensor(6., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Computation graphs\n",
    "\n",
    "a = torch.tensor(2.0, requires_grad=True) # we set requires grad=True to let pytorch know to keep the graph\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print(\"c\", c)\n",
    "print(\"d\", d)\n",
    "print(\"e\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4621, 0.5497, 0.9948, 0.7516, 0.4220, 0.0215, 0.5473, 0.1685, 0.5685,\n",
      "        0.8785])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cd03c3ff441b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m             raise RuntimeError(\n\u001b[0;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "## Cuda semantics\n",
    "cpu = torch.device(\"cpu\")\n",
    "gpu = torch.device(\"cuda\")\n",
    "\n",
    "x = torch.rand(10)\n",
    "print(x)\n",
    "x = x.to(gpu)\n",
    "print(x)\n",
    "x = x.to(cpu)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
      "Pytorch's f'(x): tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "## Pytorch as an auto grad framework\n",
    "def f(x):\n",
    "    return (x - 2)**2\n",
    "\n",
    "def fp(x):\n",
    "    return 2*(x - 2)\n",
    "\n",
    "x = torch.tensor([1.0],requires_grad=True)\n",
    "\n",
    "y = f(x)\n",
    "y.backward()\n",
    "\n",
    "print('Analytical f\\'(x):', fp(x))\n",
    "print('Pytorch\\'s f\\'(x):', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical grad g(w) tensor([2.0000, 5.2832])\n",
      "Pytorch's grad g(w) tensor([2.0000, 5.2832])\n"
     ]
    }
   ],
   "source": [
    "def g(w):\n",
    "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\n",
    "\n",
    "def grad_g(w):\n",
    "    return torch.tensor([2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])])\n",
    "\n",
    "w = torch.tensor([np.pi, 1], requires_grad=True)\n",
    "\n",
    "z = g(w)\n",
    "z.backward()\n",
    "\n",
    "print('Analytical grad g(w)', grad_g(w))\n",
    "print('Pytorch\\'s grad g(w)', w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tx,\tf(x),\tf'(x),\tf'(x) pytorch\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "format() takes at most 2 arguments (5 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0232f4f9f50a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;31m# perform a GD update step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: format() takes at most 2 arguments (5 given)"
     ]
    }
   ],
   "source": [
    "## Using the gradients\n",
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "step_size = 0.25\n",
    "\n",
    "print('iter,\\tx,\\tf(x),\\tf\\'(x),\\tf\\'(x) pytorch')\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward() # compute the gradient\n",
    "\n",
    "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}', format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
    "\n",
    "    x.data = x.data - step_size * x.grad # perform a GD update step\n",
    "\n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in, grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tx,\tf(x),\tf'(x),\tf'(x) pytorch\n",
      "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
      "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
      "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
      "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
      "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
      "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
      "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
      "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
      "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
      "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
      "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
      "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
      "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
      "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
      "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
     ]
    }
   ],
   "source": [
    "## Using the gradients\n",
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "step_size = 0.25\n",
    "\n",
    "print('iter,\\tx,\\tf(x),\\tf\\'(x),\\tf\\'(x) pytorch')\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward() # compute the gradient\n",
    "\n",
    "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'. format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
    "\n",
    "    x.data = x.data - step_size * x.grad # perform a GD update step\n",
    "\n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in, grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape torch.Size([50, 2])\n",
      "y shape torch.Size([50, 1])\n",
      "w shape torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "## Linear Regression\n",
    "\n",
    "# make a simple linear dataset with some noise\n",
    "\n",
    "d = 2\n",
    "n = 50\n",
    "X = torch.randn(n,d)\n",
    "true_w = torch.tensor([[-1.0],[2.0]])\n",
    "y = X @ true_w + torch.randn(n,1) * 0.1\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "print('w shape', true_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient [ 2.5017328 -2.8934634]\n",
      "Pytorch's gradient [ 2.5017326 -2.8934634]\n"
     ]
    }
   ],
   "source": [
    "# define a linear model with no bias\n",
    "def model(X, w):\n",
    "    return X @ w\n",
    "\n",
    "# the residual sum of squares loss function\n",
    "def rss(y, y_hat):\n",
    "    return torch.norm(y - y_hat)**2 / n\n",
    "\n",
    "# analytical expression for the gradient\n",
    "def grad_rss(X, y, w):\n",
    "    return -2*X.t() @ (y - X @ w) / n\n",
    "\n",
    "w = torch.tensor([[1.], [0]], requires_grad=True)\n",
    "y_hat = model(X, w)\n",
    "\n",
    "loss = rss(y, y_hat)\n",
    "loss.backward()\n",
    "\n",
    "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\n",
    "print('Pytorch\\'s gradient', w.grad.view(2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==与视频结果不同=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t5.37,\t[0.49965346 0.5786927 ]\n",
      "1,\t2.85,\t[0.30848873 0.7799183 ]\n",
      "2,\t2.13,\t[0.1410022  0.95148206]\n",
      "3,\t1.60,\t[-0.00546882  1.0980128 ]\n",
      "4,\t1.20,\t[-0.13336132  1.2233584 ]\n",
      "5,\t0.90,\t[-0.24488364  1.3307297 ]\n",
      "6,\t0.67,\t[-0.34202108  1.4228166 ]\n",
      "7,\t0.51,\t[-0.4265473  1.5018799]\n",
      "8,\t0.38,\t[-0.5000386  1.5698256]\n",
      "9,\t0.29,\t[-0.56389034  1.6282657 ]\n",
      "10,\t0.22,\t[-0.619333   1.6785666]\n",
      "11,\t0.17,\t[-0.6674488  1.7218894]\n",
      "12,\t0.13,\t[-0.70918715  1.7592229 ]\n",
      "13,\t0.10,\t[-0.7453792  1.7914108]\n",
      "14,\t0.07,\t[-0.77675146  1.819174  ]\n",
      "15,\t0.06,\t[-0.8039379  1.8431299]\n",
      "16,\t0.05,\t[-0.82749116  1.863807  ]\n",
      "17,\t0.04,\t[-0.84789234  1.881659  ]\n",
      "18,\t0.03,\t[-0.86556    1.8970759]\n",
      "19,\t0.03,\t[-0.88085794  1.9103924 ]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-0.88085794  1.9103924 ]\n"
     ]
    }
   ],
   "source": [
    "## Linear regression using GD with automatically computed derivatives\n",
    "step_size = 0.1\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(20):\n",
    "    y_hat = model(X, w)\n",
    "    loss = rss(y, y_hat)\n",
    "\n",
    "    loss.backward() # compute the gradient of the loss\n",
    "\n",
    "    w.data = w.data - step_size * w.grad # do a gradient descent step\n",
    "\n",
    "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), w.view(2).detach().numpy())) \n",
    "\n",
    "    # we need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach() is for efficiency. You do not need to worry too mach about is.\n",
    "    w.grad.detach()\n",
    "    w.grad.zero_() \n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', w.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-2b99fb6c8b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlinear_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mexample_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# apply a linear transformation to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Linear Module\n",
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out)\n",
    "\n",
    "example_tensor = torch([[1.,2,3], [4,5,6]])\n",
    "# apply a linear transformation to the data\n",
    "transformed = linear_module(example_tensor)\n",
    "print('example_tensor', example_tensor.shape)\n",
    "print('transormed', transformed.shape)\n",
    "print()\n",
    "print('We can see that the weights exist in the background\\n')\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor torch.Size([2, 3])\n",
      "transormed torch.Size([2, 4])\n",
      "\n",
      "We can see that the weights exist in the background\n",
      "\n",
      "W: Parameter containing:\n",
      "tensor([[-0.0772, -0.2093,  0.0958],\n",
      "        [-0.4789,  0.0069, -0.0588],\n",
      "        [-0.1015,  0.0166,  0.0020],\n",
      "        [ 0.3538, -0.4454, -0.4154]], requires_grad=True)\n",
      "b: Parameter containing:\n",
      "tensor([-0.0353,  0.2419,  0.3646,  0.2517], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Linear Module\n",
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out)\n",
    "\n",
    "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\n",
    "# apply a linear transformation to the data\n",
    "transformed = linear_module(example_tensor)\n",
    "print('example_tensor', example_tensor.shape)\n",
    "print('transormed', transformed.shape)\n",
    "print()\n",
    "print('We can see that the weights exist in the background\\n')\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor tensor([-1.,  1.,  0.])\n",
      "activated tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "## Activation function\n",
    "activation_fn = nn.ReLU() # we instantiate an instance of the ReLU module\n",
    "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
    "activated = activation_fn(example_tensor)\n",
    "print('example_tensor', example_tensor)\n",
    "print('activated', activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "## Sequential\n",
    "d_in = 3\n",
    "d_hidden = 4\n",
    "d_out = 1\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(d_in, d_hidden), nn.Tanh(), nn.Linear(d_hidden, d_out), nn.Sigmoid()\n",
    ")\n",
    "\n",
    "example_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "transformed = model(example_tensor)\n",
    "print('transformed', transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5135, -0.2740,  0.3096],\n",
      "        [ 0.1144,  0.0572,  0.1305],\n",
      "        [-0.1868,  0.4462, -0.2422],\n",
      "        [ 0.5562,  0.2181, -0.5440]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2327,  0.0183,  0.0442,  0.4625], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1062,  0.2540, -0.4678,  0.3345]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0373], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "\n",
    "for param in params:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "## Loss functions\n",
    "mes_loss_fn = nn.MSELoss()\n",
    "\n",
    "input = torch.tensor([[0., 0, 0]])\n",
    "target = torch.tensor([[1., 0, -1]])\n",
    "\n",
    "loss = mes_loss_fn(input, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-8b2bac1ccc21>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-8b2bac1ccc21>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    optim = torch.optim.SGD(model.parameters(), lr=le.2)\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## torch.optim\n",
    "\n",
    "# create a simple model\n",
    "model = nn.Linear(1,1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=le.2)\n",
    "mes_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mes_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[-0.9206]], requires_grad=True)\n",
      "model params after: Parameter containing:\n",
      "tensor([[-0.0645]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## torch.optim\n",
    "\n",
    "# create a simple model\n",
    "model = nn.Linear(1,1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "mes_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mes_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[0.1371]], requires_grad=True)\n",
      "model params after: Parameter containing:\n",
      "tensor([[0.1669]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## torch.optim\n",
    "\n",
    "# create a simple model\n",
    "model = nn.Linear(1,1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "mes_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mes_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t2.54,\t[0.20545287 0.82055604]\n",
      "1,\t1.90,\t[0.05459599 0.98980343]\n",
      "2,\t1.42,\t[-0.07817125  1.1335365 ]\n",
      "3,\t1.06,\t[-0.1947204  1.2558669]\n",
      "4,\t0.80,\t[-0.29681334  1.3601841 ]\n",
      "5,\t0.60,\t[-0.3860812  1.4492948]\n",
      "6,\t0.45,\t[-0.4640152  1.5255331]\n",
      "7,\t0.34,\t[-0.5319655  1.5908474]\n",
      "8,\t0.26,\t[-0.59114504  1.6468705 ]\n",
      "9,\t0.19,\t[-0.64263684  1.6949751 ]\n",
      "10,\t0.15,\t[-0.687403   1.7363191]\n",
      "11,\t0.11,\t[-0.7262949  1.7718817]\n",
      "12,\t0.09,\t[-0.7600629  1.8024935]\n",
      "13,\t0.07,\t[-0.78936696  1.82886   ]\n",
      "14,\t0.05,\t[-0.8147859  1.8515826]\n",
      "15,\t0.04,\t[-0.8368263  1.8711743]\n",
      "16,\t0.03,\t[-0.855931   1.8880736]\n",
      "17,\t0.03,\t[-0.87248623  1.9026557 ]\n",
      "18,\t0.02,\t[-0.8868287  1.9152424]\n",
      "19,\t0.02,\t[-0.8992515  1.9261098]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-0.8992515  1.9261098]\n"
     ]
    }
   ],
   "source": [
    "## Linear regression using GD with automatically computed derivatives and Pythorch's modules\n",
    "step_size = 0.1\n",
    "\n",
    "linear_module = nn.Linear(d, 1, bias=False)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "\n",
    "for i in range(20):\n",
    "    y_hat = linear_module(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t3.82,\t[ 0.17412634 -0.14807644]\n",
      "20,\t4.60,\t[-0.08190873  0.41125894]\n",
      "40,\t0.00,\t[-0.21793523  0.9539009 ]\n",
      "60,\t0.81,\t[-0.3078509  1.3925565]\n",
      "80,\t0.03,\t[-0.45257547  1.4924994 ]\n",
      "100,\t0.04,\t[-0.46622568  1.6491145 ]\n",
      "120,\t0.58,\t[-0.6186273  1.7372364]\n",
      "140,\t0.02,\t[-0.73122144  1.7594988 ]\n",
      "160,\t0.00,\t[-0.7914891  1.8095429]\n",
      "180,\t0.14,\t[-0.85330856  1.8732904 ]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-0.8751372  1.892002 ]\n"
     ]
    }
   ],
   "source": [
    "## Linear regression using SGD\n",
    "step_size = 0.01\n",
    "\n",
    "linear_module = nn.Linear(d, 1)\n",
    "loss_func = nn.MSELoss()\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(200):\n",
    "    rand_idx = np.random.choice(n) # take a random point from the dataset\n",
    "    x = X[rand_idx]\n",
    "    y_hat = linear_module(x)\n",
    "    loss = loss_func(y_hat, y[rand_idx]) # only compute the loss on the single point\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Neural Network Basics in pytorch\n",
    "%matplotlib inline\n",
    "\n",
    "d = 1\n",
    "n = 200\n",
    "X = torch.rand(n,d)\n",
    "y = 4 * torch.sin(np.pi * X) * torch.cos(6*np.pi*X**2)\n",
    "\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.title('plot of $f(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter, \tloss\n",
      "0,\t3.90\n",
      "600,\t3.62\n",
      "1200,\t3.61\n",
      "1800,\t3.61\n",
      "2400,\t3.61\n",
      "3000,\t3.61\n",
      "3600,\t3.60\n",
      "4200,\t3.41\n",
      "4800,\t1.34\n",
      "5400,\t0.76\n"
     ]
    }
   ],
   "source": [
    "# feel free to play with these parameters\n",
    "step_size = 0.05\n",
    "n_epochs = 6000\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "    nn.Linear(d, n_hidden_1), nn.Tanh(), nn.Linear(n_hidden_1, n_hidden_2), nn.Tanh(), nn.Linear(n_hidden_2, d_out)\n",
    ")\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size)\n",
    "print('iter, \\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print('{},\\t{:.2f}'.format(i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEdCAYAAAABymAfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZfbA8e9JCJCAEEpooUpVQAgGQQUrAhYwIooFXdfdZe2L66KwoqCLqyur8rMvrh1ULBiDDXCxgaBGAiZ0kBpAQwkoBEh5f3/cTEgmdyaTZGbulPN5njxpN3PPDeSe+7bzijEGpZRS0SvG6QCUUko5SxOBUkpFOU0ESikV5TQRKKVUlNNEoJRSUU4TgVJKRTlNBEopFeU0ESgVJUTkIhG5yOk4VOgRXVCmVOQTkebAgtJPLzDG7HUyHhVaNBEoFQVE5BngfSAWGGmMudXhkFQI0USglFJRTscIlFIqymkiUEqpKKeJQIUUEdkiIkOCdK7uIpIlIr+KyB0ejkkSkYUisl9EXhSRh0VkvI+v/52I9PRv1B7P9YqITKvimLC4FhV8dZwOQKmaEpEtwB+NMZ/V8CXuBr4wxqR4OWYSsMEYc4GIJAErgC4+vv6/gQeBy2sYn79F0rUoP9IWgYpmHYBVVRwzBHin9OMbgI+NMQU+vn4GcK6ItK5ZeH4XSdei/EgTgQq60u6fSSKyurSb4mURqW9z3Eki8oWI5IvIKhEZWe57rwPtgXki8puI3F3Nn18EnAs8Xfrz3dx+tq6IHAB6l54jG7gQ+NLtuEdF5P1yn08Xkf+JSJwx5gjwAzDUw+9hoohsKu2aWi0il9n8nv4mIj+KyAERmeP6PYlIiogsL/3ZOUCl3191rsXbdQBUdS0qzBlj9E3fgvoGbAFygHZAU2AJMK3c94YAccBG4O9AXeA84Fegu9vrDPFwDl9+/gusriVPcZ4M/Fzu8zygv9sxzYB8oC9wE5ANNC73/SeBxz28/hVAG6wHsjHAIaC12/V9V3pMU2BN6TnqAluBO0uvczRQ6Pod1uRaqrqOqq5F38L7TVsEyilPG2O2G2P2AQ8BV7t9fyDQEHjEGHPMGLMI+NDmOE9q+/Ng3RRXlvs8ESuZlDHWCt0ZwGtYffAXGWMOlDvk19Kfq8QY844xZqcxpsQYMwfYAJzmdtiTpcfsA+aVxjQQKwHMMMYUGmPeBb6vzbX4cB1er0WFN00Eyinby328Feupt7w2wHZjTInbcck+vn5tfx4q3zz3AyfYHJeF1e0yyRiz3e17J2A9aVciIteLyIrSrqt8oBfQ3O2w3eU+PoyV3NoAucaY8qtBt/rhWrxdh9drUeFNE4FySrtyH7cHdrp9fyfQTkRi3I7LLfe5t2Xxvvx8VfpQ8eb5I+A+ltAbeA54FbjR5jVOcnsN1891AF4AbgOaGWMSsbrLxIe4dgHJIlL+2PZV/IzXa/HhOsDDtajwp4lAOeVWEWkrIk2x+vHnuH3/W6w+87tFJE5EzgFGAG+VO+Zn4EQPr+/Lz1fF/eb5MXC26xMRScbqrrkJuAXoXXoe1/frAacCC21euwFWIssrPfb3WC0CXywFioA7RKSOiIyicpeSz9dS1XX4cC0qzGkiUE55A6sa5k+lbxUWQxljjgEjsWa37AGeBa43xqwtd9jDwOTSrpW/1eDnPRKRVkAToPzxrwEXiUi8iDTCupk+bozJMMYcBqZjjXe4jMRap+De2sEYsxp4DOum/jNWl8wSX2IrvbZRWFNA92MNNM+t4bU09uE6vF6LCn9adE4FnR8WgjlGRP4J/GKMmeHDsd8CfzDG5AQ+suqLpGtRtaOJQAVdOCcCpSKRdg0ppVSU0xaBUkpFOW0RKKVUlAvL6qPNmzc3HTt2dDoMpZQKKz/88MMeY0yS+9fDMhF07NiRzMxMp8NQSqmwIiK2K9C1a0gppaKcJgKllIpyIZMIRCS2dNvAD52ORSmloknIJALgL1j11pVSSgVRSCQCEWkLXAz81+lYlFIq2oREIsDaEONuoKSqA5VSSvmX49NHReQSrMJXP7iXvnU7bhwwDqB9+6pKrysVGdKzcpnwzgoKyz0ixcXA9Cv6kpZSnT12lPIsFFoEZwIjSwuRvQWcJyKz3A8yxsw0xqQaY1KTkiqth1Aq4kxOz2b8nIpJAKCwBMbPWUF6VnX22FHKM8cTgTFmkjGmrTGmI3AVsMgYM9bhsJRyVHpWLrOXbfN6zF1vr9RkoPzC8USglKps+vx1XvfhBCg2hklzszUZqFoLqURgjPnCGHOJ03Eo5bSd+QU+HVdQWMz0+esCHI2KdCGVCJRSljaJ8T4fm5tfwOT07ABGoyKdJgKlQtCEYd2Jj4v1+fhZy7ZpMlA1polAqRCUlpLMw6N6k5wYjwDJifGMHdi+QnKILSmm0ZHfyj6fVcXgslKeOL6OQCllLy0ludJagdQOTRk/ZwUxJcXMnDuNQVuyeK/XEJ4fcDnbmrRmcno209J6OxSxClfaIlAqjLgSw91fvsr5m77nmw59uDznMz5/4c88Me/f/PDh1w5HqMKRtgiUCjNj1n7JTd/N5fWUi7hv6C20+HUvf/w+nWtXfMJlq7+AvQvhvvugXz+nQ1VhIiw3r09NTTW6Q5mKSt9/T/GgwXzfsitjx0yjKPb4s1xiwUFu+GEet2R/TN3CY7B9OzRr5mCwKtSIyA/GmFT3r2vXkFLhYtcuSEsjtnUrbkmbVCEJAOTHN2LGoGv58+X3QUEBLF7sUKAq3GgiUCocHDkCo0ZBfj588AHxbVp5PHRJ085Qr54mAuUzTQRKhTpj4OabYdkyeO016NOHCcO6ezz8WJ046N8fvtaBY+UbTQRKhbpnnoFXXoEpU+DyywFr9pB4ODxGgMGD4Ycf4PDhYEWpwpgmAqVCWXEx/POfcN55cP/9Fb7laZpHiQEGDYKiIvj224CHqMKfJgKlQtmiRdYg8S23QEzFP9dkD/WIkhPj4YwzQETHCZRPNBEoFcpefx0aN4aLL670Lbt6RPFxsdb4QWIi9O6t4wTKJ5oIlApVhw7B3Llw5ZVQv36lb9vVI3p4VO/jZSkGD4alS60uIqW80JXFSjkoPSuX6fPXsTO/gDaJ8UwY1v34jTw93UoG113n8eft6hGVGTTIGmheuRJOPTUA0atIoS0CpRySnpXLpLnZ5OYXYLD2Faiw49jrr0OHDnDmmTU7weDB1nvtHlJVcDwRiEh9EflORFaKyCoRecDpmJQKhunz11FQWFzha2U7ju3aBQsXwtixlQaJfZacDJ066YCxqpLjiQA4CpxnjOkD9AWGi8hAh2NSKuA8bUe5M78A3nwTSkqsRFAbgwZZLYIwrCmmgsfxRGAsrt014krf9H+tinietqNskxgPs2ZBair06FG7kwweDL/8Ahs31u51VERzPBEAiEisiKwAfgEWGmMqrYIRkXEikikimXl5ecEPUik/8zT988EuQFaW10Finw0aZL3XcQLlRUgkAmNMsTGmL9AWOE1EetkcM9MYk2qMSU1KSgp+kEr5mafpn+dnLoDYWLjqqtqfpEcPqxS1jhMoL0IiEbgYY/KBL4DhDoeiVMDZTh3t0xpmz4bhw6FFi9qfROT4OIFSHjieCEQkSUQSSz+OB4YAa52NSqnAmpyezZ1zVlSaOrr4hXdhx47aDxKXN3iwNUawe7f/XlNFlFBYUNYaeFVEYrES09vGmA8djkmpgEnPymX2sm2VZkQUFBaT/8LLcMIJcOmlNX7tSq0M13qCxYth9OjaBa8ikuMtAmPMj8aYFGPMKcaYXsaYB52OSalAmj5/ne20uPqFRzg7+0vrZh1vP6PIG08L1D6gBSQkaPeQ8sjxRKBUtMn1sH7ggg3fcsKxghp3C3laoPboop9g4EAdMFYeaSJQKshiPOwok7b6Cw63bA3nnFOj1/W6QG3QIFixAg4erNFrq8imiUCpICux6ReKKy7kjK0/kjDmihqXlPC0QK1xfJw1YFxSYm13qZQbTQRKhYBeuzcRX3QUzjqrxq8xYVh34myaG4eOFTEvvr21NkHHCZQNTQRKhYDUHautD1wrgWsgLSWZhvUrTwQsLDY88vUOSEnRRKBsaSJQKsiaJMRV+lr/3NVsbZYMLVvW6rXzDxfafn1nfoHVPfTtt3DsWK3OoSKPJgKlgmzKiJ7ExZbrwjHGahGcWfPWgIvXQnZnnAFHjkBOTq3PoyKLJgKlgiwtJZnpo/uU1Rg6ozCPpgUH6XDp0Fq/ttd9jDt1sr6wfXutz6MiSyisLFYq6lTYYvKFF6z3tRgfKP+6gP32l7tKn/t27qz1eVRk0USglNMWL7YKzHXt6peX87iPcYsW1syh3Fy/nEdFDu0aUsppixdbrQHxsNLMX2JjoVUrbRGoSrRFoFQQuReFu69fY4b/9BPcdltwAkhOjqgWgW2RPbvWkPJKE4FSQeIqCueqB5SbX8D8/3xmbb7hh/EBnyQnw/r1wTlXgE1Oz65QxdVVZA/QZFBN2jWkVJDYFYU7ZWsOh+vWtxZ7BUObNhHRNeStlPf0+esciSmcaSJQKkjsisL137Ga5a27Q50gNc6Tk2H/fiiwL1AXDtKzcrnr7ZW2pbzBahmc+cgi0rMipwss0DQRKBUk7ou9Gh49zEm/bGZdlz5BDKKN9T5MWwWu7rVi4ykNWFzdRJoMfKOJQKkgObdHEuXnBfXLXUOsKaHH6AuDF0Ryad95mA4YPzBvVaXuNU+0m8h3jicCEWknIp+LyBoRWSUif3E6JqX8LT0rl/d+yK3QndF/x2qKY2I5c+wlwQvE1SIIw0SQnpXLfg+1lDzxtEeDqsjxRAAUAXcZY04CBgK3isjJDseklF/ZDRSn5q5mfesu0LBh8AJxtQjCsGuoJk/3nmovqYocTwTGmF3GmOWlH/8KrAF07peKKO5PpnHFhaTsXMc3rXsE9LzpWbmc+cgiOk38yBpA3fQrNGgQli0CT1t8Aowd2N5zjSVVJccTQXki0hFIAb61+d44EckUkcy8vLxgh6ZUrbg/mfbavYn6Rcf4qXvfgJ3TdjP793P4rVmLsGsRpGfl4mnddWJ8HNPSevPwqN5lhfySE+N5eFRvXU/go5BZUCYiDYH3gPHGmEobqxpjZgIzAVJTU71PGVAqxJzbI6nCvHfXRjSDbkgL2Dk9bWa/vk4j+oVZi2D6/HW200UFmDqyJ+ClxpKqUki0CEQkDisJzDbGzHU6HqX8yXagOHc1e1p34MIhgWsReBoo3VY/Mey6hjxdi0FXEfuD4y0CERHgRWCNMeZxp+MJJ+lZuUzNWEV+QeWZFHEx0KBeHAcKCrUGi8Pcn8zFlJC6YzXfnHwGgZwv1CYx3rZf/VDzlvDtMjAm8IXu/MTTtSTrYLBfhEKL4EzgOuA8EVlR+naR00GFqsnp2XSa9BEdJ37E+DkrbJMAQGEJ5BcUHu8b1sU1jnF/mj1xby5NCw7yVYtuAT2vp01qTul/Mhw9Cvv2BfT8/uS+BgN0MNifHG8RGGMWg8dxIMXxCoveZk1UpaCwmAfmrdJKjQ5wf5rtv2MVAFtPPjWg5/W0SU3vjb9aB+zcCc2aBTQGf7DrWhPg8lO9jwloZVLfOZ4IlHfXvrCUJZtq9uTW9PABuudtoUfeFrrnbaV9/m62N27JuqSOrGnRkX/s3E3m1t5MS+vt56hVeROGda9QdbR/7mr2NEjk6mvOC/i5bQdQD5dbVNY79P/t7Qa9DfD5Ws+zB9Ozcpnw7koKi630kZtfwIR3VwI6pmBHE0GISs/K5d73szl0zLfl9ADxx45w6eovuGjdEk7K20zSofyy7+2Nb8T2xFacv+k7xmQvLPv6Ly814efep9DywXvhggv8eg3K4v5kPnDnGo4NOJ20fm2dCSjMykx4agl7WzX8wLxVZUnApbDY8MC8VZoIbGgiCEHudeur0nFfLmOzPubK7M9odPQQG5q14/MTU1mX1JG1SR1Zl9SBPQmJZQODzQ/tp3veVnr8spkeeVsZuCYbhg6F22+HRx6BhIRAXl5UKnsy37cP/rULht/pXDCtW1vvw2AtgWv9gN3UUW+rhj2VoqhuiYpooYkghExOz+bNb7dXWVkRIKakmHN/yuT65R9x9ublFMbE8kn3M3mt38VkJp9MXKxUmDWUeLSobGB5T4Mm7GnQhCUdramL9QqPcs+Xr3LjU0/BwoXw+uuQmhrQa41a2dbGKZxyinMx1KsHzZuHRYvA2/oBHSj2H00EIWJyejazlm3z6dh+O9bwwGfP0/vnTexu2JTnzr2OjhPHM3JoP0Z6+Jn0rFzunLPC9o/qaFw9HhwyjkVdTuOFz58m/vTTYcoUmDgxeHXyo4UrEfTq5Wwcyclh0SKo6fqBxPg42xl1ifFx/gotooTC9NGo52sSSPptH49/+BhzZ0+gZcEBMv/xf7Tat5ubF73GhUP7ef3ZtJRkrh3Y3uv0rMUd+3LGNTPYPuRiuO8+GDwYtmyp3sUo73JyoEmT41VAndKmTVi0CDx1/1S1fmDqyJ7ExVT83x4XI2WrkFVFmggc5ksSiCsuZNy37/H5C39m5LrF8Pe/02LnFlIn3wFxvj/hTEvrzRNj+hLrZRHR/noNGZp6E98//AysWQOXXQbHjvl8DlWF7Gxrpk4QF3JVKjyXlRs2m9h7WgtRVbdQWkoy06/oU6H20PQr+uhAsQdifOiPDjWpqakmMzPT6TBqLT0rl/FzVng95vStK/nXZ8/Rfs8OuOQSeOIJ6NKl1uf11E3kEivC7Ja/MPDO38M991iDyKp2jIHERLjuOnj66aCc0m7iQXxcLO//PJ8e//0/a2FZNR4mnKDrAfxHRH4wxlQaANQOYIdMTs9mtpeWQN2iQiZ89Sp/+j7duvG/+hFc5J8F12kpyWRu3We7+bdLsTH8fm8rPrnsGjo++ihceCGcfbZfzh9Nyt/EUsxB5h48GNTxAU+F5z7YI/QwBnbvhnbtghZPTdS2mJwmkqpp11CQpWfl0veBBczychPumreVD16700oCN98MK1f6LQm4+NJNVFBYzNU9roTOneH66+HAAb/GEOncy0A3/snaWOWreq2CFoOnwdZ1sY1KDwj9AePasC3FreVWKtFEEESu/5Se6gNhDDdkZvDhq+Npd/QAzJsHzz4bsHn9aSnJPHZln0p9sOXtKqnD83+aavUn3357QOKIVO5P4z3ytgAwbWvw/uw8DbaWuNYShME4QW14ahHpXsYVaSIIIrv/lC5Jv+3nlXemMvV/M9nc93Qarl9jjQkEWFpKMg+P6u21ZfCvfYms/cMd1vqCt98OeEyRwv1pvHveFnJPSGLDEc+J1988DbZeeelA65MIbxF4ahHpXsYVaSIIIk//+QZsy+bjl29nwPYcVkz6Jz2+/wJatgxaXK6WgScGuK7VEBgwAG66KeKfIv0lMaHiIGz3vK2sS+oQ1H10XYnefeeui87tbQ0SR/i/paffte5lXJEmggArP3Uvxv2p2xj+8H06s9+6l4P1G/LCY2/S95+THKkRn5aSTJMEz7NH8o4aFk6abs0yueEGKCkJXnBhKD0rl9+OFJV9Xqe4iM57d7ChZcegr4hNS0lmycTz2PzIxSyZeJ41UBoTY5WaiPBEUNPpp9FGZw0FkGtmkGtQuHzpiIRjBTz6yZNcsvZr/nfSmRT857/cMTiwG5lXZcqInl6nlU5dU8gFTzwBf/4zPPOMjhl4MX3+OgpLjv8mO+3LpW5JEVtbncifHZqx4j57Zl7j5jSN8K4hT6W4ddZQRZoIAiQ9K9fj9Mwu+3J5du5DdN63g1V3TOL8GQ+FxE5Rrmmlnha47cwvgHv+ZI0T/POfVkKoWzfIUYYH925A10DxikRnKo66ryfIzS/g+8J4zti0lRMciSh4dC/jqoVE15CIvCQiv4hIjtOx+IunYllD1y/l/VfH000OE7twAT3/758hkQRcpqX19liPJUaE9BU74W9/s+afz9XtpT1x74PutmcbRRLD4RO7OhKP3USFnQ2aIrt2ORKPCi0hkQiAV4DhTgfhD64xgUo11I3h9iVvMvP9h9iR1B5++AHOP9+ZIKswdWRP2ymlxcZYc7CTekLXrvDUUw5EFx7c+6Z75G1hS7Nkxl/szEYwdhMVfm7YjIZHD8FvvzkQkQolIZEIjDFfAeGzgaoH5RevlFe/8AhPZzzKXYtnM7fnuWx49yNo396hKKvmbUppQWEx0xdugFtvhW++geXLHYgw9LnP1jl57zbqp/R1rIvCbpbM7hNKt6mM8AFjVbWQSAS+EJFxIpIpIpl5eZ63qHPCtS8sLdtM3r353ergHt6ZfQ8XrV3MI+fcwPJ/zGDkwM4OReq7tJRkSjzUocrNL+DDlKHQoEHQauaEo7LZOpPPJnn/LtqedZpjsUwY1p242IqJfW+j0kQQ4QPGqmphkwiMMTONManGmNSkpCSnwylzweNfeNxTuO/OdWS8died9u/knuv/QY/HpzHtMgc3JKkmb3OtJyzcyk8XXQ5vvAF79gQxqjC0ytqs3un9gYvdtm7cmdDU+kBbBFEvbBJBKErPymXDL4dsv5e26nPmvDGRgrh63HTL00x/9d6wm7lgNwfbpaCwmPuTz7bWFbz4YpAjCzMhsBnN1IxVuK/82N2wNBFEUYvAtiS30kRQGw/MW1Xpa2JKmPDlq8z48DGWJ/fgqhtnMPr6YQ5EV3uufm5PltRrCeedZ9VDKiryeFzUy862utE6dXIsBLv6VofqJfBr3fioaRFoATrPQiIRiMibwFKgu4jsEJE/OB2TN66nCveNsBOOFfD8+//k1mXv8Eaf4dwz7t/cM3ZQ2LUEyktLSfa4G1SbxHi47TbYts0qkKfs5eRAz57Wat4Q83PDZlGTCLQAnWchsaDMGHO10zH4Kj0rlwnvrKywahSgzcFf+O97/6B73lamnj+ODVf+jq/GneFQlP41YVh3281NJgzrDr1bWjOgnn7a2s1MVZadDSNGOBpCk4S4Sg8uAHsbN6dLlHQNaQE6z0LvESXETZr7Y6UkkJK7lg9e+ytt83/mxtFTeL3/SGZHSBIAz4XL0lKSrc3tb74ZFi06Piiqjvv5Z8jLc3ygeMqInpVmDQHU7dA2aloEWoDOM00E1ZCelUtBYcUht5Grv+CtNydxOK4+o677N990SeWxK/s6FGHg2BYuc/njH6FePav+kKrINVDscCJIS0lmTP92uKeCzGPxlOzcFRVFBLUAnWeaCKqhfF+imBL+9tVrPDnv36xo05206x6joEv36Nwgu3lzuPpqeO013cXMXU5p1RQHZwy5fL42r1LZkx0JTYkpKoyKKcBeW7ZRLiTGCMKFqy+x4dHDPPHhv7lg43e8ecpQ7h96Mw1PSGDJxPMcjtBBt98Or7wCL78M48c7HU3oyM6GpKSg7i/hiX2ZiXJrCVq0CHJEwacF6Oxpi6Aa2iTG037/Lt6b9TfO3ZTJ/UP+zKTht1MYG8eUET2dDs9Z/frB6afDzJlORxJasrMd7xZysesL/7lhdK4u1vUEFWkiqIZ/JeaR8fpfafHbfq4b8w9eO3UEIsLYge2j8inD/Y/px8EXwpo1sH6906GFhpISawA9BLqFwL6PPL9JaSsgSgaMQdcT2NFE4Atj4OmnGXTbtcS0acOfb3uWZR36kJwYzxNj+jItLTSe+ILJ7o/pzsOlhfR0TYFl82Y4fDhkWgR2feTjxw62yqBHUYtA1xNUpmMENtKzcpmasYr8gkLqFR7lX5//h7SsBTByJI1mzeLtEyJ9K4+q2f0xbWrQnA2tTqRrRgbcdZdDkYWQEJkxVJ5tH3mLFlHVItD1BJVpi8DN5PRsxs9ZQX5BIW3zd/Pe7LtJy1rAU4OuJv3+p0GTAOD5j+bTTv1h8WLYuzfIEYUgVyLoGeLjR23aRFUi0PUElWkiKGdyenbZNo3nbMrkw1fH0y5/N78fPYXHzrzWqsOvAM9/NCtSzrL6xj/+OMgRhaCcHKu+UMOGTkdSgfvYzu6GzaKqa0jXE1SmiaDUtS8sZdaybYgp4S+L3+Cldx9gZ6MkRvxuBp937g9Ed9PRnafKpFlJJ1LQvCVkZDgQVYgJoRlDLnZjO1/+FsfRrdudDi1odD1BZTpGgJUElmzaR+OCX3niw8c476dM3ut5LvcOu5UjcfXLjovmpqM71x+NayzFZd+RYj5om8LlH39C3NGj1orjKJGelcv0+evYmV9Ah4axLFq/nphRo5wOqwK7sZ3cBk2pl7/PKikeJf9eQV1PYIxVnbeg4PjbkSNw7Jj1VlhY8X1RUcW34mLrfZs2MCwwlYyjPhFMTs9myaZ99N+ew4x5j5F0aD+Th97CrL4XVthUPi5WorrpaCctJdm2FPenXQZw1YpP4fPPYXhEbEVdJdeTtusmW2/zJmKKi8lMaEWqw7GVZ9eq3e1aS7BrF3TsGNyAwkl+PuzYYa3C3rPHqiHl+njvXjh4EH799fjbwYPWftCHD/unhMeFF2oiCIT0rFze/GYzf/lmDnd88xbbG7dk9NhH+bF1twrHNagby0OXRXfT0RO7ipZLO/ThcFw9EjIyoiYRuD9pd9xv9bk/tzOWUNq2p01ifKU9tX8pv0FNlCWC8q24Nonx3HtaEhcV7rTWw2zZUvHNU/mUxo2hWTNo1MiaTNKyJXTtan3csCEkJEB8PNSvb70v/fiNFbv5bFM+RTGxFMbGcSy2DkUxsQzt25Zbh/SwCjrWqQOxsdb7hISA/R6iOhE89/rnvPHOIwzYsYq5Pc/lvgtu5lC9ir/sBnVjWfVgdNzM/OVonbp81akfZ7/3PvHPPFOhZRWp3G+uHfbvAuD7Ok2dCMcju5Li+12LynbscCgqZ3z05So+fn4ul+Wup/fujfTavYnkX8vth+7aTKhjRxg82Hrftq013bZ5c+utWTOoW7fa556cns0saQRdKn8vJ0+49ZRTrCSVcTxJTRjWnbQA7dIbtYlg9sQZzHnuPuqUFHPnxX/l/V6V6wTFCDx0WWgN9oWaxPg4292vPusygOEfL4WsLKv8RISLFaHYHC/p1nH/LvbFN+JQfGhNN3a1ass/Bf/pkvPgBeCnn5wNLhh274YPPoD33mPY/xZxcYmVEESIPGUAACAASURBVH9q0oYf2p7Eqy0vYVeXnjz18O+sm3wAHmJcY5KeFBtTqavRtfoZCEjPRFQmgg+HjeXaBbP5sVUX7hgxgS1N7X+xj1/ZV7uDqjB1ZE/Gz1lR6euLOvenBCEmIyMqEkH5JADQIX8nW5q0rvT1UOBxUdnGjc4EFGi5ufDOOzB3rrXGxRjo0oUX+l/GV536kdOqM7/Wa1B2uABPNW8ekFDSs3K9JgGwHio8rX5+YN6qgNyTQmL6qIgMF5F1IrJRRCYG8lyT07P5rG4r/nPaKC4fO902CcQIzBijScAXaSnJtg9N+xIas7ztSVEzjdR9O88O+3expUkbj9t8hpzOnWHTJqej8K9du6ytVDt1gjvvtAZ7778ffvwR1q9nVtrNLO1wSoUkAIGdHehLGYurB7TzOFV9/+HCgNREqjIRiMhnItLH72c+/vqxwDPAhcDJwNUicnKgzvfmt9tJ73kuD597I4WxcTbxaEugujw99C7scprVNbQ98ueol19XUa/oGG0O7iG3WXL4zDSLpESwdy/cc491Tf/5D9x4I6xbZyWAqVOttR0ijiwsq2ot0tiB7ZmW1ttrMgpETSRfWgR3A0+IyMsi0trvEcBpwEZjzE/GmGPAW8ClATgPULkJX54AT2gSqDZPT70/ppxtfRAFrYLyi5Ta5f9MDIbTh54WPv+XOne2BouPHHHk9H4pC33wIDz4IJx4IkyfDqNHw9q18Pzz0K1bpcOdWFjm7QYfHxdTVsDSWzIKxMLWKscIjDHLgfNE5HLgUxGZCzxqjPFXNMlA+UfGHcAA94NEZBwwDqB9+/Y1Ppn7oF5510ZpOena8rS5/ZgxF8BH3axEcOutDkYYHGV97xm/wYuQOuQ0p0PyqvzUyRs2H2WKMVbF1JNOCnoctR4Y/fpruOIKa4/oUaOshOBDjadgLSxz/a7dZ5eV9/CoUyrE5b5Y0yUQXVc+jRGIiADrgOeA24ENInKdn2KwG5avdKc2xsw0xqQaY1KTkmo+h+rqAe1sv35m56ZRWU7aH7w+WY0caS0sO3jQ6TCDxzXo2sVmbmCIcC81sbKutahs6YLvgh5LrctCv/ginH++NZ//u+/gvfdCqtBf+d+1ncT4ONsxyakjewat66rKFoGILAZOBFYBy4AbgLXAX0RksDFmXC1j2AGUvzu3BQJWAct1s3/z2+0UG0OsCFcPaKdJoJY8PlmNHAn//jfMn289sUWDjRshMRGahtYagvLcb75bE61e3+8Wfsfpf/ldUGOpcVnooiK4+2544gkYOhTeeguaNAlAhLVjl+jAemDytr2t3VTfCcO6OzZ99CZglTGV+lNuF5E1fojhe6CriHQCcoGrgGv88LoeTUvrrTf+YDn9dGs+dkZGdCWCrl1DeiGd+012b0Jjfq0bT+KubUGPxW61s+vrHuXnw1VXWQ8Yd9wBjz1mrb4NQZ5aAt66iVyC1XXlyxhBjpdvX1zbAIwxRSJyGzAfiAVeMsZULmCjwkr5/udn2/fj/Ix51C0utpbLRxj3MgULVq+jwVlnOh2WV5VuviJsS2xNt99+CXosnsaYPHaBbNgAI0ZYs5xmzoQ//SlIkVaft0Hv2BB6UKjVOgJjjF+WIhpjPjbGdDPGdDbGPOSP11TOce9//qRtX+oePMAXb37qdGh+l56Vy4R3VpZd6y97D1J/5w7WNmzhdGhe2U2d3NG0Nb2P5Hn4icCp1uydnBwYMMAq9PbZZ35NApPTs+k86WM6TvyIzpM+ZnJ6dq1f09s4RygtNgzNtpQKa+59ot90sGZDrJ31PueMrXUjMqRMzVhFYcnxP+i2B34h1pQwKy+OaQ7GVRW7/udOA/vQcPZ3VtnjILfcfOoC2bcPLr3UKpW9ZIk1TdRPym9KBdZN2vV5bbqRvY1zhNJiQ00Eyu/c+z73NGjCmqSO9Fqb6VBEgeM+va9DadXR1Q1aOhFOtVS6+b6wCV4ptBYAhloV0qIia0xgxw744gu/JgGwJo94+npNE0F6Vi4xHqarC97XCgRbSJSYUJHFru9zSYc+9N+x2tqUI4J1Kk0EW5sEYu1lgHXubL0PxZpD99wDCxfCc89ZExD8zFM3TU27b9Kzcpnw7kqPSSDU1ixpIlB+Z/eff0nHvtQrLmTxq5G1yrhJQsUyJR327+LXuvGUBKhoWUC51j2EWqmJ11+Hxx+36gbdeGNATuFp3Lam47kPzFtFYXHlv4MYgSfG9A25WYuaCJTf2fV9fte2J4Uxsayf/b4DEQXOlBE9iYs9frfouH8XW5u2YcrIXg5GVUPJyVZt/SAmgipLS2RmWgPC55xjJYMAia9jfyv09PWq2G3YBFBiAlNGurZ0jED53YRh3SuVpj5UL4GsNt05deNyh6IKDPdB184HdyP9+oXkH7sd96mvn7ZpxwlB6hqqsrTE7t2QlgatWsHbb0Nc5SKR/lJQaL+V5GEPX4802iJQfufpJvhNhz703r0R9u8PckSBU/5G2u6EOJIP/Ezb/qHV7PfEfZpvbn4BP9RpxoGctUE5v9fSEseOWUXj9u2D9HSoRVkZX3hbvFaTAniJ8fZJy9PXnaaJQAWE3X/4xR37EoOxag9FAPcbKdu2EVNUxPK4Zk6H5hO7G/Hmxi2J27rZc21xP/JaWuLhh60poi+/DH37BjwWbzN4pmZUf33r1JE9iYupOMAQFyNMHRk6NZDK00SgAsLuD2FVcg8KExpYC4EigKcN6/+7Kzz+rOxuxFsTW5Nw7IhVxTPAGnt4Ou5fvN9KBGPGWG9B4K0rz64CqC+vN/2KPhUWyU2/ok/IdhnqGIEKCE8Fs+Jyzob//c/h6PzD/UbaId/asD4zTFoEdjV+tpROe5358gLGTbo+YOdOz8rl0LGiSl+PE3hy2cvWoHUAB4cDxX3MJVBF4vxNE4EKGNvVokOGwMcfw7ZtUIt9JUKB+420076dHIqrT1xyGwej8p3doP620iqk65esDOi5p89fZzu9csSW72i1eJGVBNoE9/fYJCHOdraP+xRhT4K94bw/hUcbVkWOIUOs9xHQKnCv19MhfxfbmrZhwvAeDkblO7ub047GLSlBaLc/YJXgAftuqfhjR7jro+esrSRvvz2g57fjPhUYIC5WmDLCt379B+atqt2+Cg7SRKCCq1cvaNEiIhKBe7G0Lgd306hXj5B/+ivPfRX4sTpx7GyURMf83QE9r90snTu+eYvkX/Pg2WcdKSmdlpLM9NFu/fqjfevXT8/K9bh2IBBbS/qbdg2poCjfd/qf1r0469MF1DcmpGv2+6Ks+6u4GB7fDakB3UrD764e0K5CsTWArU1a0a9ob0DP6156uvOe7fzx+/fZOuJKOgwaFNBze1PT+v/eZhYFYmtJf9MWgQo492mWC9v0ov7ePP737iKnQ/Of7duhsDCkt6e0k9qhKW6Tu9iW2JoWv+wI6HkrtKaM4dHP/4Np0JAO/30qoOetjipXPZfjbWZRKBWX80QTgQq4ymWprXnh2a/NdSok/wuDfYrtTJ+/jhK3MdstTVpTL38/HDgQ0HOnpSSzZOJ5bO5zkFN/WkHdRx+xug1DgN1iu0lzs2u0uCwcugodTQQicoWIrBKREhFJdTIWFTjufaS5jVuwuUlreq/53qGIAiBME4GntQRAcGoOHTgAd90FqakhtdOY11XPNjzNLPJ1xpHTnG4R5ACjgK8cjkMFkF0f6ZIOfTl9e47VnRIJNm6E+PigT3msLbt/G9cU0qCUo542zVq89txzIbWNqddVzzZqO+PIaY4mAmPMGmNM6M+tUrVity3i951TSDhWAN9HSKtgwwarnn+M089W1WP3b/NzUmlXRqBbBNu2wVNPwfXXWy2CEOJpgLf818tvbXnX2ys5rWOTGs04CgVhM2tIRMYB4wDah/lCpGhTfpVxbn4BsSJ8mdyLEhHWvT6Xk844w+EI/WDjRujWzekoqs31bzNp7o9lFTj3x9bjt8ZNaRjoRDBlivX+wQcDe54acJ/VBNaGMrn5BaQ8uIDfjhRSvjBpsTEs2bSPsQPbh9xeA74I+OOLiHwmIjk2b5dW53WMMTONManGmNSkAFciVP6XlpJc9vRZbAz58Y3IadmZQx/Nr9EAXEgpKbGensNsfMAlc+u+CmWYSwysa9CCzcsCuLo4OxtefdVaOBaCD3blZzWBlQRcY+r7D1dMAuV52vIy1AU8ERhjhhhjetm8fRDoc6vQUnn2UB9OyV3L0xkrvPxUGMjNhaNHwzYR2N28tjRpTf1tWwJ30kmToHFj632Ics1qSk6Mx9darDXd2tJp4dWhqcKa+0Db1x1TqFtSRPvs7xyKyE/CdMaQi93Na1tia1r/uicwe0x/+SV89JGVBJo29f/r+1l1Vgbb7dcdDpyePnqZiOwATgc+EpH5TsajAst9AC6z7ckcjqvH2ZuXh3f3UJgnArub19bSKqRs3uzfkxljbUTftq0j9YRqojorg68e0C6AkQSO07OG3jfGtDXG1DPGtDTGDHMyHhVYE4Z1p/wt52iduixr15uzNv8QFoW5PNq4EerVg3bheROwu3kFbC3B3Lnw7bfWAHF86JdeAPuZVe5ECNuBYtCuIRVEaSnJlfpav+rUj077dxG7xc9PnsG0cSOceGLYTR11mZbWm7ED25e1DGJF6D+kdDqnPxNBYSH8/e/Qs6c1ZTRMuBcXbJIQR2J8XNk00Rlj+rL54YvDNglAGE0fVZEh2a2G/5cnngr/gxG7sx2MqpY2bAjbbiGXaWm9Se3QtKww4Ec7i5jQoCFx/lxU9uKLsH49ZGSE1OIxX9S0GF24CM9HGBW23JvZm5u0YUfjlozNX+NgVLVgjNUiCPNEUKm2zoEjbDihJT9nVX+/Xlu//QZTp8LgwXDJJf55TeU32iJQQVVpC8smCRQOuYC289Ph2DFri8JwsmuXNbMmzBOB/Ub2rWi4boN/TvDYY1YpifffD/vS45FIE4EKukrN7PSD8N4sWLoUzj7bucBqYkPpjTLME4HdFMltia0ZumEZFBXVbqOYjRutzeivvBJOP70WUapA0a4h5bzzzrNuNJ9+6nQk1bd6tfX+pJOcjaOW7KZIbmnSmriSYhZ8Wot6UMbArbdaLb0nnqhFhCqQNBEo5zVqZD0pzg/DZSQ5OVb8bds6HUmtuE/theNVSD9KX1zzF37nHViwAB56KOwqs0YTTQQqNAwfDllZVj9yOMnJsfZhDvN+b7upvVubtAKg0bYaTu09cADGj4dTT4VbbgGqt+uXCh5NBCo0DCtdS7hggbNxVKHCjezh/3Fs5Y9WIogAyW7dQ7tOaM62xi254cdPa7ZvxH33WYn9+echNtavu34p/9JEoEJDSgokJYV095D7jexY7k7qHsjnx8Tw7hZycZ/aaySGR4eOo/PPm+HZZ6v3YpmZ8PTT1vhA6V4D1d31SwWPJgLlqLLNPf7+CektevLbvI+tss4hyP1G1j1vKwAv7EtwKiS/cq2gbVD3eDL4qNNprE85A+6/3/duu+Ji+POfoVUr+Mc/yr6cW81dv1TwaCJQjpmcns2sZdvKql9+2bEfDQ/u59kn3nE4MnvuN6zue6xE8E18ayfCCYjMrfs4dOx4sjMi3HTq9RQdPgwTJ/r2Is8+C8uXw4wZVqlp8Nr9U52ibiowNBEox7jXwf+6UwoAhzM+diKcKrnfsLrlbSUvIZH6bVo5FJH/2e1N8FOztvw3NQ1eecVa6+HNzp1w773WmM8VV5R9eWqG5xXKE4Z1r2m4yk80ESjHuNfB39OgCTktOzN483KHIvLOvQ+9+56tbGzRIaJuZJ42Vnny9DHW9M/bbrO6fuzs2QPXXmutEH/mmQozqfILPA82R3INn3ChiUA5xq4O/ledUuiXuwYOHnQgIu/KV6GMMSV027uNFqefGlE3Mk8bqxytl2CViVi+HP7738oHLF4MffvCN9/AzJnQuXOAI1X+pIlAOcauDv5XnfoRV1IMixY5EFHVXNsX/nRTLxKOHaHzuQOdDsmvPG2sMvDEJjBmjFUC5O9/h717rW+UlFjlI845B+rXt7qObEpMN0mIs31dT19XwaWJQDnGrg5+98uGQcOGIT2NFLAWkkHErCFwmZbWmzM7V94+8rvN+0lfsROeespaKHbffZCXBxddZCWG0aOt1kK/fravO2VET+JiK7Y24mKFKSN6BuQ6VPU4WnRORKYDI4BjwCbg98aYfCdjUsE1La135Q09Zp1n1R0yJnRX7LoSQc/Iu5Gt2vlrpa8VlhimZqwibcpQa5zgySetSqL791sLxsaN8/pvVanqbGI8E4Z1j6hutXDmdPXRhcAkY0yRiPwLmATc43BMymnDhlmbl6xfD91DdCA2Jwc6dLDqDEUYTwO7ZV+fOhXefhtOOMFK2H36+PS6kb65Szhzes/iBcaYotJPlwGRsURT1Y5r45J333U2Dm9cNYaiUWKiVXU1O9vnJKBCWyiNEdwIfOLpmyIyTkQyRSQzLy8viGGpoGvfHgYNgjfesLqHQk1hIaxdG7GJoPzKYo9fT0wMv02ElEcBTwQi8pmI5Ni8XVrumHuBImC2p9cxxsw0xqQaY1KTkpICHbZy2jXXHH/qDDUbN1pz5SM0EcTF2t8WPH1dhb+AjxEYY4Z4+76I/A64BDjfmFB8/FOOGD0abr/dahWccorT0VTkSk4RmggOeBgj8PR1Ff4cTfEiMhxrcHikMeawk7Go0FBW5vmx71ja+VQOvzY79IrQ5eRATAz06OF0JAHhqfaP1gSKXE639Z4GTgAWisgKEXne4XiUg9zLPM/pNpiEXTv46tUMp0OrKCcHuna1FlBFIPdSGgDxcbERVUpDVeTo9FFjTHjv+K38yr3M88IuAzhSpy67nnsJfp/mYGRucnJCr7vKj3TOf/Rxeh2BUmXcyzwfqpfAZ10GcP6qr/jguy1celrHoMeUnpVb4YZ4z9ntGblxozWYHcF0zn90cbprSKkydn3QGSedRfPDB/jyubeCHo/d1oqvvli64jlCB4pVdNJEoEKGXR/0FyemcrBeA87MXBj0eOy2Vuyw+yfrA00EKoJoIlAhIy0luVI1ymN14vik2xkMW7+UjKUbgxqP3RaK3fK2cjS2DnTR4S0VOTQRqJAyZURP3EuXfXDy2TQ8VsC3T78e1Fjsuqq679nKthYdoI4Or1WlbCrwxI8485FFXrerVM7SRKBCSlpKMu6rCpe1780vDZowOMjdQ3bTKLvv2Ub9vpE7Y8hf0rNymfDOygrjKxPeWanJIERpIlAhJ9ntSbwkJpYPewzm3J8yIT94VcrL70gmQLf6xbQ5mEe7s04LWgzhamrGKgpLKqZ0VylrFXo0EaiQM2FY90qbmHxw8tnUKypk+YyXghqLa0eyzY9czIKhza0v6kBxlaosZa1CiiYCFXLSUpJpULdiH/zK1t3Yktia4tke6xIGXoTuSqaUJgIVkioVOBMh46Sz6LdpBeze7UxQOTnWNprt2ztz/jCiexSHF00EKiTZzdj54ORziDUl8FJwu4fK5ORYW1PG6J9NVXSP4vCi/6NVSLKbsbOzdUd2DzoPHn8cfq28r27ARfGuZNWdCpqWksz00X3KBtqTE+OZPrqPlq0IUToZWoUkT4XPWo14GAYMgGeegYkTgxfQzz9DXl5UJgJXqQ3XKuvc/AImzbX2ZPB2Y9d6ReFDE4EKWfY3kmS48EL497/h1lutDdSDIYoHiu1KbRQUFvPAvFV6o48Q2jWkws+UKbB3r9UqCJalS633vXsH75whwq7UBsD+w4W6QCxCaCJQ4WfAgOOtgt9+C/z5jIHXX4ezzoKWLQN/vhDjbWey6fPXBTESFShOb1X5DxH5sXR3sgUi0sbJeFQYCWarYNkyWL8efve7wJ8rBHnbmcxTa0GFF6dbBNONMacYY/oCHwL3OxyPChcDBsDw4TB9euBbBa++CgkJcMUVgT1PiEpLSSYx3n7+v+5jHBkcTQTGmIPlPm0AleqNKVXGfQrjl1fdHPhWQUEBvPUWjBoVvIHpEDR1ZE/dxziCOd0iQEQeEpHtwLV4aRGIyDgRyRSRzLy8vOAFqEKC3W5hN22sy89nnBPYsYKMDDhwAG64ITCvHybKF+ADiBWhoLCY6fPX6YBxBBBjAvsQLiKfAa1svnWvMeaDcsdNAuobY6ZU9ZqpqakmMzPTj1GqUHfmI4vItemPHnpwMzOfux3+9S+4+27/n/jCC2HVKtiyRVcUU3lNAVgrhhvUrcOBgkLd6D7EicgPxphU968H/H+2MWaIMaaXzdsHboe+AVwe6HhUePI0KLmwUScYNiwwYwU7d8KCBXD99ZoEStmtKSgsNuQXFB7fd+Bd3Xcg3Dg9a6hruU9HAmudikWFNk+DkjEifHnVLbBnj9Uq8KdZs6CkJGpnC9nxZZZQYbHhgXm670A4cfox5xERyRGRH4GhwF8cjkeFKLvaQwDFxnDTprpsu/hyeOgh+OQT/5zQGHjlFTjjDOjatcrDo4Wvs4T2H9Z9B8KJ07OGLi/tJjrFGDPCGKPtSWXLNVgZK+47GlvlDm447UY45RS45hrYtKn2J8zMhDVron6Q2J2nhKzCm9MtAqV8lpaSTImHyQ2bDxuYO9f6ZNQoOHy4did75RWoXx+uvLJ2rxNh3GcPeeJp3YEKTZoIVFjx1DXRJjEeTjwR3ngDsrNh3Dire6cmjh6FN9+Eyy6Dxo1rEW1kcm3fOXag5w16po7UfQfCiSYCFVbsuiYqLGy68EJ48EGYPRuefrpmJ5k3D/bv10HiKkxL683Yge2JKddbFx8Xw4wxfXX6aJgJ+DqCQNB1BNEtPSu30j4FFW48JSXW0/zHH8OiRTB4cPVOcMklkJUF27ZBrPaHq8jhaR2B7kegwk6VG57ExMBrr0H//lZ9oOXLoY19PUP3pDL51CZc+OmnMGGCJgEVNbRrSEWmxo3h/fetRWb9+1uJoaSkwiEXPP4F4+esKCtbcWzHTorv/CsUF2u3kIoqmghU5OrZ0+oaSk62buwDBsDXXwNw7QtL2fDLIQCaHD7AxM9f4qv//JHhq7/ijcFXQo8eTkauVFBp15AKe17HDE47zdpP4I03YNIka3OZyy9nW/MLaVS/IX/87n1u/CGDhGNHSO95Dk+ecRVbmyZzjbOXpFRQaSJQYc2njdVjYmDsWGt9wWOPUfTPh/ms8AOO1qlHo6OH+LD7IGYMuoaNza3pkFXNkVcq0mgiUGHN08bq0+evqzygnJAA993H5QXdufKTl2l4tIDnB17OmhYnVjhMa+yraKOJQIU1T0XQcvMLOPORRbYlkX8sacDKYbfZ/lzXFg10DryKOjpYrMKatyJorm4i95LInn4mLgYW/vUcf4anVFjQFoEKaxOGda+0UUp5BYXFjJ+zgqkZqxCB/MOFJCbEERcjFJYcX0wZHxfLw6N6BytspUKKJgIV1lzdONPnr7Pdwcwlv+B4WeT9hwuJixUS4+N0Vy2l0ESgIoBrpbGn7SztFBYbGtSrw4opQwMcnVKhT8cIVMSobq18X3bbUioaaItARQxfu4lcfN1tS6lIFxItAhH5m4gYEWnudCwqvLlq5c8Y09dr60DQ9QJKuTieCESkHXABsM3pWFTkcO2kZbdTlgDXDmyvg8NKlXI8EQBPAHcD4bcxggppaSnJrJgylBlj+pKcGI9glY94YkxfpqXpVFGlXBwdIxCRkUCuMWal2GxK7nbsOGAcQPv2nrfIU8pdlfsXKBXlAp4IROQzoJXNt+4F/g74NH/PGDMTmAnWDmV+C1AppaJcwBOBMWaI3ddFpDfQCXC1BtoCy0XkNGPM7kDHpZRSyuJY15AxJhto4fpcRLYAqcaYPU7FpJRS0SgUBouVUko5KGQWlBljOjodg1JKRSMxJvzGXUUkD9hay5dpDkRTN5Reb+SLtmvW662+DsaYJPcvhmUi8AcRyTTGpDodR7Do9Ua+aLtmvV7/0TECpZSKcpoIlFIqykVzIpjpdABBptcb+aLtmvV6/SRqxwiUUkpZorlFoJRSCk0ESikV9SI+EYjIcBFZJyIbRWSizffricic0u9/KyIdgx+l//hwvX8VkdUi8qOI/E9EOjgRp79Udb3ljhtduvlRWE839OV6ReTK0n/jVSLyRrBj9Dcf/k+3F5HPRSSr9P/1RU7E6Q8i8pKI/CIiOR6+LyLyZOnv4kcR6eeXExtjIvYNiAU2AScCdYGVwMlux9wCPF/68VXAHKfjDvD1ngsklH58c6Rfb+lxJwBfAcuw6lk5HnsA/327AllAk9LPWzgddxCueSZwc+nHJwNbnI67Ftd7FtAPyPHw/YuAT7D2VxoIfOuP80Z6i+A0YKMx5idjzDHgLeBSt2MuBV4t/fhd4HypanOE0FXl9RpjPjfGHC79dBlW1ddw5cu/L8A/gEeBI8EMLgB8ud4/Ac8YY/YDGGN+CXKM/ubLNRugUenHjYGdQYzPr4wxXwH7vBxyKfCasSwDEkWkdW3PG+mJIBnYXu7zHaVfsz3GGFMEHACaBSU6//Plesv7A9bTRbiq8npFJAVoZ4z5MJiBBYgv/77dgG4iskRElonI8KBFFxi+XPNUYKyI7AA+Bm4PTmiOqO7fuE9CpuhcgNg92bvPl/XlmHDh87WIyFggFTg7oBEFltfrFZEYrK1QbwhWQAHmy79vHazuoXOwWntfi0gvY0x+gGMLFF+u+WrgFWPMYyJyOvB66TWXBD68oAvI/SrSWwQ7gHblPm9L5WZj2TEiUgeraemtaRbKfLleRGQI1g5xI40xR4MUWyBUdb0nAL2AL0r3uxgIZITxgLGv/58/MMYUGmM2A+uwEkO48uWa/wC8DWCMWQrUxyrQFol8+huvrkhPBN8DXUWkk4jUxRoMznA7JgP4XenHo4FFpnRUJgxVeb2lXSX/wUoC4d5/7PV6jTEHjDHNjTEdjVXmfBnWdWc6E26t+fL/G2YqEwAAAZpJREFUOR1rQgAi0hyrq+inoEbpX75c8zbgfAAROQkrEeQFNcrgyQCuL509NBA4YIzZVdsXjeiuIWNMkYjcBszHmn3wkjFmlYg8CGQaYzKAF7GakhuxWgJXORdx7fh4vdOBhsA7pWPi24wxIx0LuhZ8vN6I4eP1zgeGishqoBiYYIzZ61zUtePjNd8FvCAid2J1k9wQrg9zIvImVrde89IxjylAHIAx5nmsMZCLgI3AYeD3fjlvmP6+lFJK+Umkdw0ppZSqgiYCpZSKcpoIlFIqymkiUEqpKKeJQCmlopwmAqWUinKaCJRSKsppIlDKD0rr4V9Q+vE0EXnS6ZiU8lVEryxWKoimAA+KSAsgBQjL1doqOunKYqX8RES+xCrfcY4x5len41HKV9o1pJQfiEhvoDVwVJOACjeaCJSqpdIdomZj7R51SESGORySUtWiiUCpWhCRBGAucJcxZg3WtphTHQ1KqWrSMQKllIpy2iJQSqkop4lAKaWinCYCpZSKcpoIlFIqymkiUEqpKKeJQCmlopwmAqWUinL/Dzv6DgL0/gAXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter, \tloss\n",
      "0,\t3.48\n",
      "150,\t0.01\n",
      "300,\t0.01\n",
      "450,\t0.01\n",
      "600,\t0.01\n",
      "750,\t0.01\n",
      "900,\t0.01\n",
      "1050,\t0.01\n",
      "1200,\t0.01\n",
      "1350,\t0.00\n"
     ]
    }
   ],
   "source": [
    "## Things that might help the homework\n",
    "\n",
    "# feel free to play with these parameters\n",
    "\n",
    "step_size = 0.05\n",
    "momentum = 0.9\n",
    "n_epochs = 1500\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "    nn.Linear(d, n_hidden_1), nn.Tanh(), nn.Linear(n_hidden_1, n_hidden_2), nn.Tanh(), nn.Linear(n_hidden_2, d_out)\n",
    ")\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size, momentum=momentum)\n",
    "print('iter, \\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print('{},\\t{:.2f}'.format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== 收敛速度更快 =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-cd3a32c16122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'plot of $f(x)$ and $\\hat{f}(x)$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2846\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2847\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[1;32m-> 2848\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2849\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2850\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4441\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4443\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "## CrossEntropyloss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "input = torch.tensor([[-1.,1],[-1,1],[1,-1]]) # raw scores correspond to the correct class\n",
    "# input = torch.tensor([[-3.,3],[-3,3],[3,-3]]) # raw scores correspond to the correct class with higher confidence\n",
    "# input = torch.tensor([[1.,-1],[1,-1],[-1,1]]) # raw scores correspond to the incorrect class\n",
    "# input = torch.tensor([[3.,-3],[3,-3],[-3,3]]) # raw scores correspond to the incorrect class with higher confidence\n",
    "\n",
    "target = torch.tensor([1,1,0])\n",
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 28, 28]' is invalid for input of size 31",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-fb6e94b9d938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# an entire mnist digit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimage_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 1, 28, 28]' is invalid for input of size 31"
     ]
    }
   ],
   "source": [
    "## Convolutions\n",
    "\n",
    "# an entire mnist digit\n",
    "image = np.array([0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.])\n",
    "image_torch = torch.from_numpy(image).view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-83548d445a62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mconvolved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'original image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_torch' is not defined"
     ]
    }
   ],
   "source": [
    "# a gaussian blur kernel\n",
    "gaussian_kernel = torch.tensor([[1.,2,1],[2,4,2],[1,2,1]]) / 16.0\n",
    "\n",
    "conv= nn.Conv2d(1,1,3)\n",
    "# manually set the conv weight\n",
    "conv.weight.data[:] = gaussian_kernel\n",
    "\n",
    "convolved = conv(image_torch)\n",
    "\n",
    "plt.title('original image')\n",
    "plt.imshow(image_torch.view(28,28).detach().numpy*())\n",
    "plt.show()\n",
    "\n",
    "plt.title('blurred image')\n",
    "plt.imshow(convolved.view(26,26).detach().numpy())\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FakeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12172, 12268, 15416, 6540) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-5abb2824d95c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 12172, 12268, 15416, 6540) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 10)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "dataset = FakeDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "== 数据大小不一样，使用collate_fn=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-387b9e792485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## apex.amp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# declare module and optimizer as usual, with default (FP32) precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "## apex.amp\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "# declare module and optimizer as usual, with default (FP32) precision\n",
    "model = torch.nn.Linear(10, 100).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# allow amp to perform casts as required by the opt_level\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"01\")\n",
    "\n",
    "# loss.backward() becomes:\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    scaled_loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==英伟达的apex=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
