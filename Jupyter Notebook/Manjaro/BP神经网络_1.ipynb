{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acting-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNNet(\n",
      "  (hidden): Linear(in_features=3, out_features=6, bias=True)\n",
      "  (out): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 0, Training loss 203374192.0, Validation loss 203374192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fern/miniconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Training loss 5827211.5, Validation loss 5827211.5\n",
      "Epoch 1000, Training loss 5760077.0, Validation loss 5760077.0\n",
      "Epoch 1500, Training loss 5669951.5, Validation loss 5669951.5\n",
      "Epoch 2000, Training loss 5557067.5, Validation loss 5557067.5\n",
      "Epoch 2500, Training loss 5423532.5, Validation loss 5423532.5\n",
      "Epoch 3000, Training loss 5294457.5, Validation loss 5294457.5\n",
      "Epoch 3500, Training loss 5218053.5, Validation loss 5218053.5\n",
      "Epoch 4000, Training loss 5190337.0, Validation loss 5190337.0\n",
      "Epoch 4500, Training loss 5177390.5, Validation loss 5177390.5\n",
      "Epoch 5000, Training loss 5170036.5, Validation loss 5170036.5\n",
      "Epoch 5500, Training loss 5166805.5, Validation loss 5166805.5\n",
      "Epoch 6000, Training loss 5165862.0, Validation loss 5165862.0\n",
      "Epoch 6500, Training loss 5165698.0, Validation loss 5165698.0\n",
      "Epoch 7000, Training loss 5165682.5, Validation loss 5165682.5\n",
      "Epoch 7500, Training loss 5165682.0, Validation loss 5165682.0\n",
      "Epoch 8000, Training loss 5165681.5, Validation loss 5165681.5\n",
      "Epoch 8500, Training loss 5165682.0, Validation loss 5165682.0\n",
      "Epoch 9000, Training loss 5165682.0, Validation loss 5165682.0\n",
      "Epoch 9500, Training loss 5165682.0, Validation loss 5165682.0\n"
     ]
    }
   ],
   "source": [
    "# 可视化\n",
    "import torch\n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"/home/fern/Downloads/ANNData.csv\", dtype=np.float32)\n",
    "\n",
    "x = train.drop(['Response'], axis=1)\n",
    "y = train['Response']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2021)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.values)\n",
    "y_train = torch.from_numpy(y_train.values).type(torch.LongTensor)\n",
    "\n",
    "x_test = torch.from_numpy(x_test.values)\n",
    "y_test = torch.from_numpy(y_test.values).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 2\n",
    "iteration_num = 100\n",
    "\n",
    "class ANNNet(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(ANNNet, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.hidden(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "net = ANNNet(n_input=3, n_hidden=6, n_output=1)\n",
    "print(net)\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.5)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(10000):\n",
    "    x_train = x_train.to(torch.float32)\n",
    "    y_train = y_train.to(torch.float32)\n",
    "    x_test = x_test.to(torch.float32)\n",
    "    y_test = y_test.to(torch.float32)\n",
    "    prediction_train = net(x_train)\n",
    "    prediction_train = prediction_train.to(torch.float32)\n",
    "    loss_train = loss_func(prediction_train, y_train)\n",
    "    \n",
    "    prediction_test = net(x_test)\n",
    "    prediction_test = prediction_test.to(torch.float32)\n",
    "    loss_test = loss_func(prediction_train, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print('Epoch %d, Training loss %.1f, Validation loss %.1f' % (i, float(loss_train), float(loss_test)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clear-notice",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-156f951b29ff>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-156f951b29ff>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m visdom.server\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m visdom.server\n",
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-injury",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
